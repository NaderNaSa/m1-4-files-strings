{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Workshop Python Intro.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPMuPsz+efoYpJzg8ElS0Ut"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"colab":{},"colab_type":"code","id":"Bg811t1qthd4"},"source":["# Warmup: Counter. \n","\n","Count how many times each element in a list occurs.\n","\n","```\n","[1, 3, 2, 1, 5, 3, 5, 1, 4] â‡’\n","\n","    1: 3 times\n","    2: 1 time\n","    3: 2 times\n","    4: 1 time\n","    5: 2 times\n","```\n"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["1 :  3 times\n2 :  1 time\n3 :  2 times\n4 :  1 time\n5 :  2 times\n"]}],"source":["from collections import Counter\n","# declaring the list \n","l = [1, 3, 2, 1, 5, 3, 5, 1, 4]\n","# driver program \n","d = Counter(l) \n","for i in set(l):\n","    if (d[i] > 1) :\n","        print('{} :  {} times'.format(i, d[i])) \n","    else:\n","        print('{} :  {} time'.format(i, d[i])) "]},{"cell_type":"markdown","metadata":{},"source":["# Safe dict reading\n","\n","define a function `safe_dict(d, k)` that takes in a python dict `d` and a key `k` and makes it safe to read even with keys that aren't in the dictionary. If you try to read from the dictionary with a bad key, it should return 0 instead.\n","\n","```\n","d = {1 : 2, 3 : 4}\n","safe_dict(d, 1) -> 2\n","safe_dict(d, 'cat') -> 0\n","```"]},{"cell_type":"code","execution_count":125,"metadata":{},"outputs":[],"source":["def safe_dict(d,k):\n","    try:\n","        result = d[k]\n","    except KeyError as ke:\n","        result = 0\n","    return result"]},{"cell_type":"code","execution_count":128,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["2\n0\n"]}],"source":["print(safe_dict({1:2,3:4},1))\n","print(safe_dict({1:2,3:4},'cat'))"]},{"cell_type":"markdown","metadata":{"colab":{},"colab_type":"code","id":"tl_ZhkbEtiTD"},"source":["# File Reading: Hamlet Exercises\n","\n","Open `hamlet.txt` in the `data` folder\n","\n","### 1. Mentionned Hamlet\n","\n","How many times is hamlet mentioned in the book?\n","\n","Use python and line iteration to count it up"]},{"cell_type":"code","execution_count":47,"metadata":{"tags":[]},"outputs":[],"source":["'''\n","open the file\n","read contecnt of the file to string\n","then get number of accurences \n","'''\n","def count_hamlet() :\n","    occurrances=0\n","    f = open(\"data\\hamlet.txt\",\"r\")\n","    data = f.read().upper()\n","    occurrances = data.count(\"HAMLET\")\n","    print(f\"Number of occurrences of the word HAMLET is: {occurrances}\")\n","    #f.close\n","    return occurrances"]},{"cell_type":"code","execution_count":51,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of occurrences of the word HAMLET is: 474\n474\n"]}],"source":["print(count_hamlet())"]},{"cell_type":"markdown","metadata":{},"source":["### 2. File Reading as a .py program\n","\n","Make a python file that defines a function that counts the number of times hamlet is mentionned using the code in the previous exercise.\n","\n","Then import it in your notebook and call it here."]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of occurrences of the word HAMLET is: 474\n"]},{"output_type":"execute_result","data":{"text/plain":["474"]},"metadata":{},"execution_count":52}],"source":["\n","import find_hamlet\n","count_hamlet()"]},{"cell_type":"markdown","metadata":{},"source":["### 3. Unique words in hamlet\n","\n","Write a program that counts the unique words in hamlet."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def count_unique_words() :\n","    file =  open(\"data\\hamlet.txt\",\"r\")\n","    lines = file.read().splitlines()\n","\n","    uniques = set()\n","    for line in lines:\n","        uniques |= set(line.split())\n","\n","    return print(f\"Unique words: {len(uniques)}\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Unique words: 7676\nNone\n"]}],"source":["print(count_unique_words())"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["9219"]},"metadata":{},"execution_count":1}],"source":["import re\n","regex = re.compile('\\s+')\n","\n","def uniquewords(datafile):\n","    data_file = open(datafile, 'r')\n","    readfile = data_file.read().replace('\\n', '')\n","    count_unique = len(set(regex.split(readfile)))\n","    data_file.close()\n","    return count_unique\n","\n","uniquewords('data/hamlet.txt')"]},{"cell_type":"markdown","metadata":{},"source":["# File Reading 2: A Python library.\n","\n","In the `data` folder, you will find a folder called `csrgraph` which is a python library.\n","\n","### 1. File count\n","\n","Count the `py` files in the library using the `os` package"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["8\n"]}],"source":["import os\n","count=0\n","for file in os.listdir(\"..\\data\\csrgraph\"):\n","    if file.endswith(\".py\"):\n","        count += 1\n","print(count)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### 2. For the following packages, count the number of files that import them:\n","\n","- pandas \n","\n","- numpy\n","\n","- numba"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#that import all of them or one of them"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["pandas :   4\nnumpy :   6\nnumba :   6\nsklearn :   4\nNone\n"]}],"source":["'''\n","loop packages\n","loop files for each package\n","search for the packed in the file\n","\n","'''\n","def countimportfiles(packages):\n","    path= \"..\\data\\csrgraph\"\n","    fileslist = os.listdir(path)\n","    count= 0\n","    for p in packages:\n","        count = 0\n","        for f in fileslist:\n","            if f.endswith(\".py\"):\n","                file =  open(path + '/' + f,\"r\")\n","                openfile = file.read()\n","                if  openfile.find('import '+p) != -1 or openfile.find('from '+p) != -1:\n","                    count += 1\n","                \n","        print (f\"{p} :   {str(count)}\" )\n","\n","print(countimportfiles([\"pandas\",\"numpy\",\"numba\",\"sklearn\"]))    "]},{"cell_type":"markdown","metadata":{},"source":["# First NLP Program: IDF\n","\n","Given a list of words, the the inverse document frequency (IDF) is a basic statistic of the amount of information of each word in the text.\n","\n","The IDF formulat is:\n","\n","$$IDF(w) = ln(\\dfrac{N}{1 + n(w)})$$\n","\n","Where:\n","\n","- $w$ is the token (unique word),\n","- $n(w)$ is the number of documents that $w$ occurs in,\n","- $N$ is the total number of documents\n","\n","Write a function, `idf(docs)` that takes in a list of lists of words and returns a dictionary  `word -> idf score`\n","\n","Example:\n","\n","```\n","IDF([['interview', 'questions'], ['interview', 'answers']]) -> {'questions': 0.0, \n","                                                                'interview': -0.4, \n","                                                                'answers': 0.0}\n","\n","\n","```"]},{"cell_type":"code","execution_count":164,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["answers : 0.0\ninterview : -0.40546510810816444\nquestions : 0.0\n"]}],"source":["import numpy as np\n","\n","def IDF(docs):\n","    #get the lsit of unqiue word\n","    u_words = np.unique(docs)\n","    N = len(docs)\n","    ln=len(u_words)\n","    #loop unique words\n","    word_document_frequency = []\n","    for uw in u_words:\n","\n","        #loop documents\n","        uw_count=0\n","        for d in docs:\n","            if bool(np.intersect1d(uw,d)) == True:\n","                uw_count += 1\n","            \n","        word_document_frequency.append((uw,uw_count))\n","    \n","    for w in range(len(word_document_frequency)):\n","        result = np.log(N/(1 + (word_document_frequency[w][1])))\n","        print(f\"{word_document_frequency[w][0]} : {result}\")\n","  \n","IDF([['interview', 'questions'], ['interview', 'answers']])"]},{"cell_type":"markdown","metadata":{"colab":{},"colab_type":"code","id":"82bfnc_KueoX"},"source":["# Stretch Goal: IDF on Hamlet\n","\n","Calculate the IDF dictionary on the Hamlet book.\n","\n","What's the IDF of \"Hamlet\"?\n","\n","What's the word with the highest IDF in the book?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}